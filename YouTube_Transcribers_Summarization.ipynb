{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPh/J2UB0P4cEn2PAMCtqu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2678d8a86ce4a24b83ae02ead15ce0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54f953626d044bc2b8b9e4a22fbe6734",
              "IPY_MODEL_33cfd6acbc8f48ef8fc217301d920328",
              "IPY_MODEL_c2b155839cbd49a9a98af0eec4d1a456"
            ],
            "layout": "IPY_MODEL_a1d45e4375ad4f2b9f81cfc158acf2c3"
          }
        },
        "54f953626d044bc2b8b9e4a22fbe6734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62511542d4144bdaa31c557e7c7ef9aa",
            "placeholder": "​",
            "style": "IPY_MODEL_eb8749ee25b14d76bc93cd212409e5a3",
            "value": "Summarizing chunks: 100%"
          }
        },
        "33cfd6acbc8f48ef8fc217301d920328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42dc67931a154136beb1878682f2f153",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b639ec2274554bdaa7f1a64c5704852a",
            "value": 2
          }
        },
        "c2b155839cbd49a9a98af0eec4d1a456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cab3df483044e8880939dc3a5930e5",
            "placeholder": "​",
            "style": "IPY_MODEL_9dba4114af094147b4a2333ac9169974",
            "value": " 2/2 [00:02&lt;00:00,  1.03s/it]"
          }
        },
        "a1d45e4375ad4f2b9f81cfc158acf2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62511542d4144bdaa31c557e7c7ef9aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8749ee25b14d76bc93cd212409e5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dc67931a154136beb1878682f2f153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b639ec2274554bdaa7f1a64c5704852a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49cab3df483044e8880939dc3a5930e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dba4114af094147b4a2333ac9169974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ✨ **YouTube Transcript API** ✨\n",
        "\n",
        "Install the following package: https://pypi.org/project/youtube-transcript-api/"
      ],
      "metadata": {
        "id": "_k43KkAuQawM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38bgaLhuN6mh",
        "outputId": "e980cee6-4fd1-4215-c996-0d161071860d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "BokYQIaTOvqB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace**: https://huggingface.co/sshleifer/distilbart-cnn-12-6\n",
        "\n",
        "**ModelName**: sshleifer/distilbart-cnn-12-6"
      ],
      "metadata": {
        "id": "KRaioGCHP2_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YouTubeSummarizer:\n",
        "  def __init__(self, model_name=\"sshleifer/distilbart-cnn-12-6\", max_chunk_size=1000):\n",
        "\n",
        "      self.summarizer = pipeline('summarization', model=model_name)\n",
        "      self.max_chunk_size = max_chunk_size\n",
        "\n",
        "  def extract_video_id(self, youtube_url):\n",
        "\n",
        "      # Handle different URL formats (standard, shortened, embedded, etc.)\n",
        "      patterns = [\n",
        "          r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',  # Standard and embedded URLs\n",
        "          r'(?:youtu\\.be\\/)([0-9A-Za-z_-]{11})',  # Shortened URLs\n",
        "      ]\n",
        "\n",
        "      for pattern in patterns:\n",
        "          match = re.search(pattern, youtube_url)\n",
        "          if match:\n",
        "              return match.group(1)\n",
        "\n",
        "      raise ValueError(f\"Could not extract video ID from URL: {youtube_url}\")\n",
        "\n",
        "  def get_transcript(self, video_id):\n",
        "      try:\n",
        "          transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "          transcript = ' '.join([item['text'] for item in transcript_list])\n",
        "          return transcript\n",
        "      except Exception as e:\n",
        "          raise Exception(f\"Error retrieving transcript: {str(e)}\")\n",
        "\n",
        "  def split_into_chunks(self, text):\n",
        "      # Split by sentences first (simple approach)\n",
        "      sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "      chunks = []\n",
        "      current_chunk = \"\"\n",
        "\n",
        "      for sentence in sentences:\n",
        "          # If adding this sentence exceeds the chunk size, start a new chunk\n",
        "          if len(current_chunk) + len(sentence) > self.max_chunk_size:\n",
        "              # If the current chunk is not empty, add it to chunks\n",
        "              if current_chunk:\n",
        "                  chunks.append(current_chunk.strip())\n",
        "                  current_chunk = sentence\n",
        "              else:\n",
        "                  # If a single sentence is longer than max_chunk_size, force split it\n",
        "                  chunks.append(sentence[:self.max_chunk_size])\n",
        "                  current_chunk = sentence[self.max_chunk_size:]\n",
        "          else:\n",
        "              current_chunk += \" \" + sentence\n",
        "\n",
        "      # Add the last chunk if not empty\n",
        "      if current_chunk:\n",
        "          chunks.append(current_chunk.strip())\n",
        "\n",
        "      return chunks\n",
        "\n",
        "  def summarize_text(self, text, min_length=30, max_length=150):\n",
        "\n",
        "      # Split text into chunks that the model can handle\n",
        "      chunks = self.split_into_chunks(text)\n",
        "\n",
        "      # Summarize each chunk\n",
        "      summaries = []\n",
        "      for chunk in tqdm(chunks, desc=\"Summarizing chunks\"):\n",
        "          # Skip chunks that are too short to summarize meaningfully\n",
        "          if len(chunk) < 100:\n",
        "              summaries.append(chunk)\n",
        "              continue\n",
        "\n",
        "          summary = self.summarizer(chunk,\n",
        "                                    max_length=max_length,\n",
        "                                    min_length=min_length,\n",
        "                                    do_sample=False)\n",
        "          summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "      # Combine the summaries\n",
        "      full_summary = ' '.join(summaries)\n",
        "\n",
        "      # For very long texts with many chunks, we might want to summarize again\n",
        "      if len(chunks) > 3:\n",
        "          # Re-summarize if the combined summary is still long\n",
        "          if len(full_summary) > self.max_chunk_size:\n",
        "              chunks = self.split_into_chunks(full_summary)\n",
        "              second_level_summaries = []\n",
        "\n",
        "              for chunk in tqdm(chunks, desc=\"Creating final summary\"):\n",
        "                  summary = self.summarizer(chunk,\n",
        "                                          max_length=max_length,\n",
        "                                          min_length=min_length,\n",
        "                                          do_sample=False)\n",
        "                  second_level_summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "              full_summary = ' '.join(second_level_summaries)\n",
        "\n",
        "      return full_summary\n",
        "\n",
        "  def summarize_youtube_video(self, youtube_url, min_length=30, max_length=150):\n",
        "\n",
        "      # Extract the video ID\n",
        "      video_id = self.extract_video_id(youtube_url)\n",
        "\n",
        "      # Get the transcript\n",
        "      transcript = self.get_transcript(video_id)\n",
        "\n",
        "      # Summarize the transcript\n",
        "      summary = self.summarize_text(transcript, min_length, max_length)\n",
        "\n",
        "      return {\n",
        "          'video_id': video_id,\n",
        "          'transcript_length': len(transcript),\n",
        "          'summary_length': len(summary),\n",
        "          'compression_ratio': len(summary) / len(transcript) if len(transcript) > 0 else 0,\n",
        "          'summary': summary\n",
        "      }"
      ],
      "metadata": {
        "id": "Q4380DedO4sZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our summarizer\n",
        "youtube_summarizer = YouTubeSummarizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tByrl-j3POsG",
        "outputId": "2a631407-11bc-42ed-cee3-c22f702578c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with a video\n",
        "video_url = \"https://www.youtube.com/watch?v=KbYu85euDvY\""
      ],
      "metadata": {
        "id": "59fUSpcAPWF_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = youtube_summarizer.summarize_youtube_video(video_url)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "b2678d8a86ce4a24b83ae02ead15ce0f",
            "54f953626d044bc2b8b9e4a22fbe6734",
            "33cfd6acbc8f48ef8fc217301d920328",
            "c2b155839cbd49a9a98af0eec4d1a456",
            "a1d45e4375ad4f2b9f81cfc158acf2c3",
            "62511542d4144bdaa31c557e7c7ef9aa",
            "eb8749ee25b14d76bc93cd212409e5a3",
            "42dc67931a154136beb1878682f2f153",
            "b639ec2274554bdaa7f1a64c5704852a",
            "49cab3df483044e8880939dc3a5930e5",
            "9dba4114af094147b4a2333ac9169974"
          ]
        },
        "id": "gMEsFzWtPYnA",
        "outputId": "12265059-308f-477a-dc95-bf1181f97c6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Summarizing chunks:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2678d8a86ce4a24b83ae02ead15ce0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'video_id': 'KbYu85euDvY',\n",
              " 'transcript_length': 5022,\n",
              " 'summary_length': 723,\n",
              " 'compression_ratio': 0.14396654719235363,\n",
              " 'summary': ' OpenAI launched its advanced AI image generator last week . Users quickly began using it They rendered image after image . They turned everything from memes to selfies into copies of the Japanese studios work . This spurred a global outage of chat GPT over the weekend and forced its top boss to say \"Please chill This is insane\"  Chat GPT\\'s freefor-all Giblly cuteness may come at a cost Tech giants train their models without disclosing details . this data to train its AI models . Your photo could be misused and manipulated It could be manipulated and sold for targeted ads If the data is stolen it could even end up on the dark web And if this sounds scary that\\'s because it is None of these risks are unprecedented .'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results nicely\n",
        "print(f\"Video ID: {result['video_id']}\")\n",
        "print(f\"Transcript length: {result['transcript_length']} characters\")\n",
        "print(f\"Summary length: {result['summary_length']} characters\")\n",
        "print(f\"Compression ratio: {result['compression_ratio']:.2%}\")\n",
        "print(\"\\nSUMMARY:\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Wrap the text for nice display\n",
        "wrapped_summary = textwrap.fill(result['summary'], width=80)\n",
        "print(wrapped_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCXA6nVbPbcc",
        "outputId": "65df9861-8610-4a8f-9929-8d9fbd077452"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video ID: KbYu85euDvY\n",
            "Transcript length: 5022 characters\n",
            "Summary length: 723 characters\n",
            "Compression ratio: 14.40%\n",
            "\n",
            "SUMMARY:\n",
            "================================================================================\n",
            " OpenAI launched its advanced AI image generator last week . Users quickly began\n",
            "using it They rendered image after image . They turned everything from memes to\n",
            "selfies into copies of the Japanese studios work . This spurred a global outage\n",
            "of chat GPT over the weekend and forced its top boss to say \"Please chill This\n",
            "is insane\"  Chat GPT's freefor-all Giblly cuteness may come at a cost Tech\n",
            "giants train their models without disclosing details . this data to train its AI\n",
            "models . Your photo could be misused and manipulated It could be manipulated and\n",
            "sold for targeted ads If the data is stolen it could even end up on the dark web\n",
            "And if this sounds scary that's because it is None of these risks are\n",
            "unprecedented .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upIqm0vfPtDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}